{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from DataSets import LyricsDataset\n",
    "from Data_Reader import Spotify_Data_Reader\n",
    "from Bert_Trainer import Bert_Trainer\n",
    "\n",
    "reader = Spotify_Data_Reader()\n",
    "x_test, y_test, x_val, y_val = reader.read_test_val()\n",
    "x_train, y_train, x_train_backtrans, y_train_backtrans, x_train_classical, y_train_classical, x_train_llm, y_train_llm = reader.read_training()\n",
    "num_labels = reader.get_num_labels()\n",
    "class_weights = reader.get_class_weights(mode='noaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1/10...\n",
      "computing batch 1551/1552\n",
      "Epoch 1/10 Results                  \n",
      "Training loss: 2.2166914853084947\n",
      "Training accuracy: 0.1986466892218463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\unsee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\unsee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\unsee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9606262334843272\n",
      "Validation Accuracy: 0.22100515463917525\n",
      "\n",
      "Running Epoch 2/10...\n",
      "computing batch 1551/1552\n",
      "Epoch 2/10 Results                  \n",
      "Training loss: 2.2386609661517682\n",
      "Training accuracy: 0.18696632833897212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\unsee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\unsee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\unsee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9883965210816295\n",
      "Validation Accuracy: 0.15077319587628865\n",
      "\n",
      "stopping early..\n",
      "Validation Report for lr=5e-05, batch_size=8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       430\n",
      "           1       0.22      1.00      0.36       343\n",
      "           2       0.00      0.00      0.00       234\n",
      "           3       0.00      0.00      0.00       241\n",
      "           4       0.00      0.00      0.00       180\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00        17\n",
      "           7       0.00      0.00      0.00        21\n",
      "           8       0.00      0.00      0.00        37\n",
      "           9       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.22      1552\n",
      "   macro avg       0.02      0.10      0.04      1552\n",
      "weighted avg       0.05      0.22      0.08      1552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  [5e-05, 8]\n",
      "best val_acc:  0.22100515463917525\n",
      "best val report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       430\n",
      "           1       0.22      1.00      0.36       343\n",
      "           2       0.00      0.00      0.00       234\n",
      "           3       0.00      0.00      0.00       241\n",
      "           4       0.00      0.00      0.00       180\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00        17\n",
      "           7       0.00      0.00      0.00        21\n",
      "           8       0.00      0.00      0.00        37\n",
      "           9       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.22      1552\n",
      "   macro avg       0.02      0.10      0.04      1552\n",
      "weighted avg       0.05      0.22      0.08      1552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer = Bert_Trainer(num_labels=num_labels, dataset=LyricsDataset, model_save_name=\"spotify_noaug_bert\", class_weights=class_weights)\n",
    "\n",
    "\n",
    "\n",
    "best_val_acc = 0\n",
    "best_report = None\n",
    "best_params = None\n",
    "\n",
    "for lr in [5e-5]:\n",
    "    for batch_size in [8]:\n",
    "\n",
    "        trainer.load_data(x_train, y_train, x_test, y_test, x_val, y_val, batch_size=batch_size)\n",
    "        val_acc, val_loss, report = trainer.train(lr=lr, epochs=10, early_stopping=True, early_stopping_tol=0.02)\n",
    "        print(f'Validation Report for lr={lr}, batch_size={batch_size}')\n",
    "        print(report)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_report = report\n",
    "            best_params = [lr, batch_size]\n",
    "            trainer.save_model(\"spotify_noaug_bert\") # f'spot_noaug_bert_{lr}_{batch_size}'\n",
    "        trainer.reset_model()\n",
    "    \n",
    "print('best params: ', best_params)\n",
    "print('best val_acc: ', best_val_acc)\n",
    "print('best val report:')\n",
    "print(best_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1/10...\n",
      "computing batch 10/1552\r"
     ]
    }
   ],
   "source": [
    "from Bert_Trainer import Bert_Trainer\n",
    "\n",
    "trainer = Bert_Trainer(num_labels=num_labels, dataset=LyricsDataset, model_save_name='spotify_noaug_bert')\n",
    "\n",
    "trainer.load_data(x_train, y_train, x_test, y_test, x_val, y_val, batch_size=8)\n",
    "\n",
    "trainer.train(lr=5e-5, epochs=10)\n",
    "\n",
    "trainer.save_model()\n",
    "\n",
    "trainer.evaluate(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights=reader.get_class_weights(mode='backtrans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1/10...\n",
      "computing batch 2062/2063\n",
      "Epoch 1/10 Results                  \n",
      "Training loss: 1.3206161904467926\n",
      "Training accuracy: 0.5427549845463912\n",
      "Validation Loss: 1.1507387425481659\n",
      "Validation Accuracy: 0.5947164948453608\n",
      "\n",
      "Running Epoch 2/10...\n",
      "computing batch 2062/2063\n",
      "Epoch 2/10 Results                  \n",
      "Training loss: 0.7312382885511789\n",
      "Training accuracy: 0.7504999696988062\n",
      "Validation Loss: 1.018307664806081\n",
      "Validation Accuracy: 0.6591494845360825\n",
      "\n",
      "Running Epoch 3/10...\n",
      "computing batch 2062/2063\n",
      "Epoch 3/10 Results                  \n",
      "Training loss: 0.4438526077187876\n",
      "Training accuracy: 0.8535846312344706\n",
      "Validation Loss: 1.10239672572496\n",
      "Validation Accuracy: 0.6694587628865979\n",
      "\n",
      "Running Epoch 4/10...\n",
      "computing batch 2062/2063\n",
      "Epoch 4/10 Results                  \n",
      "Training loss: 0.27733100082235923\n",
      "Training accuracy: 0.9126113568874613\n",
      "Validation Loss: 1.4049524379193246\n",
      "Validation Accuracy: 0.6391752577319587\n",
      "\n",
      "stopping early..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6417525773195877,\n",
       " 1.1820561533275338,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.79      0.62      0.70       448\\n           1       0.66      0.84      0.74       341\\n           2       0.53      0.43      0.48       239\\n           3       0.73      0.71      0.72       234\\n           4       0.42      0.59      0.49       182\\n           5       0.86      0.55      0.67        11\\n           6       0.80      0.33      0.47        12\\n           7       0.73      0.42      0.54        26\\n           8       0.29      0.27      0.28        30\\n           9       0.72      0.79      0.75        29\\n\\n    accuracy                           0.64      1552\\n   macro avg       0.65      0.56      0.58      1552\\nweighted avg       0.66      0.64      0.64      1552\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bert_Trainer import Bert_Trainer\n",
    "\n",
    "trainer = Bert_Trainer(num_labels=num_labels, dataset=LyricsDataset, model_save_name='spotify_backtrans_bert')\n",
    "\n",
    "trainer.load_data(x_train_backtrans, y_train_backtrans, x_test, y_test, x_val, y_val, batch_size=8)\n",
    "\n",
    "trainer.train(lr=5e-5, epochs=10)\n",
    "\n",
    "trainer.save_model()\n",
    "\n",
    "trainer.evaluate(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 1/10 Results                  \n",
      "Training loss: 1.2191903703420084\n",
      "Training accuracy: 0.5668423284269186\n",
      "Validation Loss: 1.1721429813307584\n",
      "Validation Accuracy: 0.5747422680412371\n",
      "\n",
      "Running Epoch 2/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 2/10 Results                  \n",
      "Training loss: 0.7226234721525233\n",
      "Training accuracy: 0.7522563450239264\n",
      "Validation Loss: 1.0143513341155863\n",
      "Validation Accuracy: 0.6462628865979382\n",
      "\n",
      "Running Epoch 3/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 3/10 Results                  \n",
      "Training loss: 0.4578285955268052\n",
      "Training accuracy: 0.852262402326004\n",
      "Validation Loss: 1.0787025036808757\n",
      "Validation Accuracy: 0.648840206185567\n",
      "\n",
      "Running Epoch 4/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 4/10 Results                  \n",
      "Training loss: 0.29124853360649855\n",
      "Training accuracy: 0.9095039069598401\n",
      "Validation Loss: 1.3022472366844255\n",
      "Validation Accuracy: 0.6436855670103093\n",
      "\n",
      "Running Epoch 5/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 5/10 Results                  \n",
      "Training loss: 0.19348545511298978\n",
      "Training accuracy: 0.9394875522442304\n",
      "Validation Loss: 1.491538525275771\n",
      "Validation Accuracy: 0.6527061855670103\n",
      "\n",
      "Running Epoch 6/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 6/10 Results                  \n",
      "Training loss: 0.1497224575976206\n",
      "Training accuracy: 0.9558422678538979\n",
      "Validation Loss: 1.4025466383828484\n",
      "Validation Accuracy: 0.6391752577319587\n",
      "\n",
      "Running Epoch 7/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 7/10 Results                  \n",
      "Training loss: 0.1315303121534038\n",
      "Training accuracy: 0.9614755587861167\n",
      "Validation Loss: 1.6326924183636367\n",
      "Validation Accuracy: 0.6475515463917526\n",
      "\n",
      "Running Epoch 8/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 8/10 Results                  \n",
      "Training loss: 0.10262473527363063\n",
      "Training accuracy: 0.9695317705493973\n",
      "Validation Loss: 1.6182402063103527\n",
      "Validation Accuracy: 0.6527061855670103\n",
      "\n",
      "Running Epoch 9/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 9/10 Results                  \n",
      "Training loss: 0.0953547716082201\n",
      "Training accuracy: 0.9717729723181295\n",
      "Validation Loss: 1.6951298888379074\n",
      "Validation Accuracy: 0.657860824742268\n",
      "\n",
      "Running Epoch 10/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 10/10 Results                  \n",
      "Training loss: 0.08636653647716216\n",
      "Training accuracy: 0.9754679265854989\n",
      "Validation Loss: 1.793939017947552\n",
      "Validation Accuracy: 0.6404639175257731\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6533505154639175,\n",
       " 1.7861337229932333,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.73      0.71      0.72       448\\n           1       0.69      0.79      0.74       341\\n           2       0.52      0.51      0.52       239\\n           3       0.71      0.68      0.69       234\\n           4       0.51      0.47      0.49       182\\n           5       1.00      0.64      0.78        11\\n           6       0.38      0.50      0.43        12\\n           7       0.86      0.46      0.60        26\\n           8       0.32      0.20      0.24        30\\n           9       0.66      0.86      0.75        29\\n\\n    accuracy                           0.65      1552\\n   macro avg       0.64      0.58      0.60      1552\\nweighted avg       0.65      0.65      0.65      1552\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Bert_Trainer(num_labels=num_labels, dataset=LyricsDataset, model_save_name='spotify_classical_bert')\n",
    "\n",
    "trainer.load_data(x_train_classical, y_train_classical, x_test, y_test, x_val, y_val, batch_size=8)\n",
    "\n",
    "trainer.train(lr=5e-5, epochs=10)\n",
    "\n",
    "trainer.save_model()\n",
    "\n",
    "trainer.evaluate(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 1/10 Results                  \n",
      "Training loss: 1.3246275511129881\n",
      "Training accuracy: 0.5192319340965534\n",
      "Validation Loss: 1.0564577302981897\n",
      "Validation Accuracy: 0.6378865979381443\n",
      "\n",
      "Running Epoch 2/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 2/10 Results                  \n",
      "Training loss: 0.9204464268928408\n",
      "Training accuracy: 0.6703010479132594\n",
      "Validation Loss: 1.0478172574153881\n",
      "Validation Accuracy: 0.663659793814433\n",
      "\n",
      "Running Epoch 3/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 3/10 Results                  \n",
      "Training loss: 0.6489389746029348\n",
      "Training accuracy: 0.7658852746986492\n",
      "Validation Loss: 1.1922247310447478\n",
      "Validation Accuracy: 0.6559278350515464\n",
      "\n",
      "Running Epoch 4/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 4/10 Results                  \n",
      "Training loss: 0.46403333370694744\n",
      "Training accuracy: 0.8324550245320734\n",
      "Validation Loss: 1.3464081668626209\n",
      "Validation Accuracy: 0.6643041237113402\n",
      "\n",
      "Running Epoch 5/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 5/10 Results                  \n",
      "Training loss: 0.3774095606288959\n",
      "Training accuracy: 0.8624992428372403\n",
      "Validation Loss: 1.3845273686822541\n",
      "Validation Accuracy: 0.6469072164948454\n",
      "\n",
      "Running Epoch 6/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 6/10 Results                  \n",
      "Training loss: 0.31748638500760906\n",
      "Training accuracy: 0.8841843842752438\n",
      "Validation Loss: 1.4546717009639136\n",
      "Validation Accuracy: 0.6572164948453608\n",
      "\n",
      "Running Epoch 7/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 7/10 Results                  \n",
      "Training loss: 0.2951005351185517\n",
      "Training accuracy: 0.8898782482282391\n",
      "Validation Loss: 1.5161513492834668\n",
      "Validation Accuracy: 0.6507731958762887\n",
      "\n",
      "Running Epoch 8/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 8/10 Results                  \n",
      "Training loss: 0.27821049182154617\n",
      "Training accuracy: 0.8973287297837543\n",
      "Validation Loss: 1.5834820724966139\n",
      "Validation Accuracy: 0.6494845360824743\n",
      "\n",
      "Running Epoch 9/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 9/10 Results                  \n",
      "Training loss: 0.2561535694471257\n",
      "Training accuracy: 0.9017505603004422\n",
      "Validation Loss: 1.7076574720960764\n",
      "Validation Accuracy: 0.6514175257731959\n",
      "\n",
      "Running Epoch 10/10...\n",
      "computing batch 2063/2064\n",
      "Epoch 10/10 Results                  \n",
      "Training loss: 0.21434490977283482\n",
      "Training accuracy: 0.9176206917438973\n",
      "Validation Loss: 2.221898750392432\n",
      "Validation Accuracy: 0.6192010309278351\n",
      "\n",
      "stopping early..\n"
     ]
    }
   ],
   "source": [
    "from Bert_Trainer import Bert_Trainer\n",
    "\n",
    "trainer = Bert_Trainer(num_labels=num_labels, dataset=LyricsDataset, model_save_name='spotify_llm_bert')\n",
    "\n",
    "trainer.load_data(x_train_llm, y_train_llm, x_test, y_test, x_val, y_val, batch_size=8)\n",
    "\n",
    "trainer.train(lr=5e-5, epochs=10, early_stopping=True, early_stopping_tol=0.02)\n",
    "\n",
    "trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
